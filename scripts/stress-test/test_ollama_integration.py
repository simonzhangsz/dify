"""
æµ‹è¯• Ollama é›†æˆ
"""
import requests
import json


def test_ollama_direct():
    """ç›´æ¥æµ‹è¯• Ollama API"""
    print("ğŸ§ª Testing Ollama API directly...")
    
    ollama_host = "http://172.17.0.1:11434"
    
    # æµ‹è¯•æ¨¡å‹åˆ—è¡¨
    try:
        response = requests.get(f"{ollama_host}/api/tags", timeout=5)
        if response.status_code == 200:
            models = response.json().get('models', [])
            print("âœ… Connection successful!")
            print(f"   Available models: {len(models)}")
            for model in models:
                print(f"   - {model['name']}")
        else:
            print(f"âŒ Failed to get models: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ Connection failed: {e}")
        return False
    
    # æµ‹è¯•ç”Ÿæˆ
    print("\nğŸ§ª Testing model generation...")
    try:
        model_name = models[0]['name'] if models else 'deepseek-r1:latest'
        response = requests.post(
            f"{ollama_host}/api/generate",
            json={
                'model': model_name,
                'prompt': 'ä»€ä¹ˆæ˜¯å¤§è¯­è¨€æ¨¡å‹ï¼Ÿè¯·ç”¨ä¸€å¥è¯å›ç­”ã€‚',
                'stream': False
            },
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            print("âœ… Generation successful!")
            print(f"   Model: {model_name}")
            print(f"   Response: {result.get('response', '')[:100]}...")
            return True
        else:
            print(f"âŒ Generation failed: {response.status_code}")
            print(f"   Error: {response.text}")
            return False
            
    except Exception as e:
        print(f"âŒ Generation test failed: {e}")
        return False


def test_dify_ollama():
    """æµ‹è¯•é€šè¿‡ Dify API ä½¿ç”¨ Ollama"""
    print("\nğŸ§ª Testing Ollama via Dify API...")
    print("âš ï¸  This requires Dify API server to be running and a workflow configured with Ollama")
    print("   To test manually:")
    print("   1. Start Dify API: cd /workspaces/dify.git/api && uv run gunicorn --bind 0.0.0.0:5001 --workers 4 --worker-class gevent app:app")
    print("   2. Open Web UI: http://localhost:3000")
    print("   3. Create a workflow using Ollama model")
    print("   4. Get API key from Settings â†’ API Access")
    print("   5. Run the workflow via API")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 60)
    print("OLLAMA INTEGRATION TEST")
    print("=" * 60)
    print()
    
    # ç›´æ¥æµ‹è¯• Ollama
    success = test_ollama_direct()
    
    if success:
        print("\n" + "=" * 60)
        print("âœ… OLLAMA IS READY TO USE!")
        print("=" * 60)
        print("\nğŸ“ Configuration Summary:")
        print("   - Ollama Host: http://172.17.0.1:11434")
        print("   - Connection: âœ… Working")
        print("   - Model Generation: âœ… Working")
        print("\nğŸ’¡ Next Steps:")
        print("   1. Start Dify API server")
        print("   2. Configure Ollama in Dify Web UI")
        print("   3. Create workflows using Ollama models")
    else:
        print("\n" + "=" * 60)
        print("âŒ OLLAMA SETUP INCOMPLETE")
        print("=" * 60)
        print("\nğŸ”§ Troubleshooting:")
        print("   1. Ensure Ollama is running on host:")
        print("      ollama serve")
        print("   2. Ensure Ollama is listening on 0.0.0.0:")
        print("      export OLLAMA_HOST=0.0.0.0:11434")
        print("      ollama serve")
        print("   3. Verify connection from container:")
        print("      curl http://172.17.0.1:11434/api/tags")
    
    # Dify é›†æˆè¯´æ˜
    test_dify_ollama()


if __name__ == '__main__':
    main()
