"""
é…ç½® Ollama æ¨¡å‹æä¾›å•†è¿æ¥åˆ°å®¿ä¸»æœº
"""
import os
import sys
import json

# æ·»åŠ  api ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '../../..', 'api'))

def configure_ollama():
    """é…ç½® Ollama æä¾›å•†ä½¿ç”¨å®¿ä¸»æœºçš„æœåŠ¡"""
    
    # Docker ç½‘æ¡¥ IPï¼ˆä» Dev Container è®¿é—®å®¿ä¸»æœºï¼‰
    ollama_host = "http://172.17.0.1:11434"
    
    print("ğŸ”§ Configuring Ollama provider...")
    print(f"   Host: {ollama_host}")
    
    # æµ‹è¯•è¿æ¥
    import requests
    try:
        response = requests.get(f"{ollama_host}/api/tags", timeout=5)
        if response.status_code == 200:
            models = response.json().get('models', [])
            print(f"\nâœ… Connection successful!")
            print(f"ğŸ“‹ Available models:")
            for model in models:
                print(f"   - {model['name']}")
            
            # ä¿å­˜é…ç½®åˆ°ç¯å¢ƒå˜é‡æ–‡ä»¶
            env_file = os.path.join(os.path.dirname(__file__), '../../../api/.env')
            
            # è¯»å–ç°æœ‰ .env æ–‡ä»¶
            env_lines = []
            if os.path.exists(env_file):
                with open(env_file, 'r') as f:
                    env_lines = f.readlines()
            
            # æ›´æ–°æˆ–æ·»åŠ  Ollama é…ç½®
            ollama_config_found = False
            new_env_lines = []
            for line in env_lines:
                if line.startswith('OLLAMA_API_BASE_URL='):
                    new_env_lines.append(f'OLLAMA_API_BASE_URL={ollama_host}\n')
                    ollama_config_found = True
                elif line.startswith('OLLAMA_API_KEY='):
                    new_env_lines.append('OLLAMA_API_KEY=ollama\n')
                else:
                    new_env_lines.append(line)
            
            # å¦‚æœé…ç½®ä¸å­˜åœ¨ï¼Œæ·»åŠ å®ƒ
            if not ollama_config_found:
                new_env_lines.append('\n# Ollama Configuration\n')
                new_env_lines.append(f'OLLAMA_API_BASE_URL={ollama_host}\n')
                new_env_lines.append('OLLAMA_API_KEY=ollama\n')
            
            # å†™å›æ–‡ä»¶
            with open(env_file, 'w') as f:
                f.writelines(new_env_lines)
            
            print(f"\nâœ… Configuration saved to {env_file}")
            print(f"\nğŸ’¡ Next steps:")
            print(f"   1. Restart Dify API server:")
            print(f"      cd /workspaces/dify.git/api")
            print(f"      uv run gunicorn --bind 0.0.0.0:5001 --workers 4 --worker-class gevent app:app")
            print(f"   2. Open Dify Web UI: http://localhost:3000")
            print(f"   3. Go to Settings â†’ Model Provider â†’ Ollama")
            print(f"   4. Enter Base URL: {ollama_host}")
            print(f"   5. Save and select Ollama models in your workflows")
            
        else:
            print(f"âŒ Connection failed: {response.status_code}")
            print(f"   Response: {response.text}")
            
    except Exception as e:
        print(f"âŒ Connection test failed: {e}")
        print(f"\nâš ï¸  Please ensure:")
        print(f"   1. Ollama is running on the host machine")
        print(f"   2. Ollama is listening on 0.0.0.0:11434 (not just 127.0.0.1)")
        print(f"   3. Run on host: export OLLAMA_HOST=0.0.0.0:11434 && ollama serve")


if __name__ == '__main__':
    configure_ollama()
