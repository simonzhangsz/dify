# Ollama é›†æˆæŒ‡å—

## âœ… é…ç½®å®Œæˆ

Ollama å·²æˆåŠŸé…ç½®å¹¶å¯ä» Dify Dev Container è®¿é—®ï¼

## ğŸ“‹ é…ç½®æ‘˜è¦

- **Ollama ä¸»æœº**: `http://172.17.0.1:11434`
- **è¿æ¥çŠ¶æ€**: âœ… æ­£å¸¸
- **å¯ç”¨æ¨¡å‹**: `deepseek-r1:latest`
- **é…ç½®ä½ç½®**: `/workspaces/dify.git/api/.env`

## ğŸš€ åœ¨ Dify ä¸­ä½¿ç”¨ Ollama

### æ–¹æ³• 1: é€šè¿‡ Web UI é…ç½®ï¼ˆæ¨èï¼‰

1. **å¯åŠ¨ Dify æœåŠ¡**:
   ```bash
   cd /workspaces/dify.git/api
   uv run gunicorn \
     --bind 0.0.0.0:5001 \
     --workers 4 \
     --worker-class gevent \
     --timeout 120 \
     app:app
   ```

2. **æ‰“å¼€ Web UI**: `http://localhost:3000`

3. **é…ç½® Ollama æä¾›å•†**:
   - è¿›å…¥ **Settings** â†’ **Model Provider**
   - æ‰¾åˆ° **Ollama** éƒ¨åˆ†
   - é…ç½®ï¼š
     ```
     Base URL: http://172.17.0.1:11434
     API Key: ollama  (ä»»æ„å€¼ï¼ŒOllama ä¸éœ€è¦çœŸå®çš„ API key)
     ```
   - ç‚¹å‡» **Validate** æµ‹è¯•è¿æ¥
   - ç‚¹å‡» **Save** ä¿å­˜

4. **åˆ›å»ºå·¥ä½œæµä½¿ç”¨ Ollama**:
   - åˆ›å»ºæ–°çš„ Chatflow æˆ– Workflow
   - æ·»åŠ  LLM èŠ‚ç‚¹
   - åœ¨ Model é€‰æ‹©å™¨ä¸­é€‰æ‹© **Ollama** æä¾›å•†
   - é€‰æ‹©æ¨¡å‹ï¼š`deepseek-r1:latest`
   - é…ç½®æç¤ºè¯å¹¶æµ‹è¯•

### æ–¹æ³• 2: é€šè¿‡ API ä½¿ç”¨

```python
import requests

# Dify API ç«¯ç‚¹
DIFY_API = "http://localhost:5001/v1"
API_KEY = "your-api-key-here"  # ä» Dify Web UI è·å–

# åˆ›å»ºä½¿ç”¨ Ollama çš„å¯¹è¯
response = requests.post(
    f"{DIFY_API}/chat-messages",
    headers={
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    },
    json={
        "inputs": {},
        "query": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±",
        "response_mode": "blocking",
        "user": "test-user"
    }
)

print(response.json()["answer"])
```

## ğŸ”§ éªŒè¯é…ç½®

è¿è¡Œå¿«é€Ÿæµ‹è¯•ç¡®è®¤ä¸€åˆ‡æ­£å¸¸ï¼š

```bash
cd /workspaces/dify.git
uv run --project api python scripts/stress-test/test_ollama_quick.py
```

åº”è¯¥çœ‹åˆ°ï¼š
```
âœ… OLLAMA IS READY!
```

## ğŸ“¦ å®‰è£…æ›´å¤šæ¨¡å‹

åœ¨**å®¿ä¸»æœº**ä¸Šæ‹‰å–æ›´å¤š Ollama æ¨¡å‹ï¼š

```bash
# è½»é‡çº§æ¨¡å‹ï¼ˆæ¨èç”¨äºå¼€å‘ï¼‰
ollama pull qwen2.5:3b        # 1.9GB - ä¸­æ–‡ä¼˜åŒ–
ollama pull llama3.2:3b       # 2.0GB - è‹±æ–‡ä¼˜åŒ–
ollama pull phi3:mini         # 2.3GB - å¾®è½¯

# ä¸­ç­‰æ¨¡å‹
ollama pull qwen2.5:7b        # 4.7GB - æ›´å¼ºä¸­æ–‡èƒ½åŠ›
ollama pull llama3.2:7b       # 4.7GB - æ›´å¼ºè‹±æ–‡èƒ½åŠ›
ollama pull mistral:7b        # 4.1GB - å¹³è¡¡æ€§èƒ½

# æŸ¥çœ‹å·²å®‰è£…æ¨¡å‹
ollama list
```

æ‹‰å–æ–°æ¨¡å‹åï¼Œå®ƒä»¬ä¼šè‡ªåŠ¨åœ¨ Dify çš„æ¨¡å‹é€‰æ‹©å™¨ä¸­å‡ºç°ã€‚

## ğŸ› æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: è¿æ¥å¤±è´¥

**ç—‡çŠ¶**: `Connection refused` æˆ– `timeout`

**è§£å†³æ–¹æ¡ˆ**:

1. ç¡®è®¤ Ollama åœ¨å®¿ä¸»æœºè¿è¡Œï¼š
   ```bash
   # åœ¨å®¿ä¸»æœºæ‰§è¡Œ
   curl 127.0.0.1:11434/api/tags
   ```

2. ç¡®è®¤ Ollama ç›‘å¬æ‰€æœ‰ç½‘ç»œæ¥å£ï¼š
   ```bash
   # åœ¨å®¿ä¸»æœºæ‰§è¡Œ
   sudo netstat -tlnp | grep 11434
   # åº”è¯¥çœ‹åˆ° 0.0.0.0:11434ï¼Œè€Œä¸æ˜¯ 127.0.0.1:11434
   ```

3. å¦‚æœåªç›‘å¬ localhostï¼Œé‡æ–°é…ç½® Ollamaï¼š
   ```bash
   # åœ¨å®¿ä¸»æœºæ‰§è¡Œ
   export OLLAMA_HOST=0.0.0.0:11434
   ollama serve
   ```

### é—®é¢˜ 2: æ¨¡å‹æœªæ˜¾ç¤º

**ç—‡çŠ¶**: Dify UI ä¸­çœ‹ä¸åˆ° Ollama æ¨¡å‹

**è§£å†³æ–¹æ¡ˆ**:

1. éªŒè¯æ¨¡å‹å·²ä¸‹è½½ï¼š
   ```bash
   # åœ¨å®¿ä¸»æœºæ‰§è¡Œ
   ollama list
   ```

2. æµ‹è¯•ä» Dev Container è®¿é—®ï¼š
   ```bash
   curl http://172.17.0.1:11434/api/tags
   ```

3. é‡æ–°ä¿å­˜ Dify ä¸­çš„ Ollama é…ç½®

### é—®é¢˜ 3: ç”Ÿæˆè¶…æ—¶

**ç—‡çŠ¶**: è¯·æ±‚è¶…æ—¶æˆ–å“åº”å¾ˆæ…¢

**è§£å†³æ–¹æ¡ˆ**:

1. **ä½¿ç”¨æ›´å°çš„æ¨¡å‹**:
   ```bash
   ollama pull qwen2.5:3b  # æ›¿ä»£ deepseek-r1
   ```

2. **å¢åŠ  Dify API è¶…æ—¶**:
   ```bash
   # ç¼–è¾‘ gunicorn å¯åŠ¨å‘½ä»¤
   uv run gunicorn \
     --bind 0.0.0.0:5001 \
     --workers 4 \
     --worker-class gevent \
     --timeout 300 \  # å¢åŠ åˆ° 5 åˆ†é’Ÿ
     app:app
   ```

3. **è°ƒæ•´æ¨¡å‹å‚æ•°**ï¼ˆåœ¨ Dify UI ä¸­ï¼‰:
   - é™ä½ Max Tokens (å¦‚ 512 æˆ–æ›´å°‘)
   - å¢åŠ  Temperature å¯èƒ½åŠ å¿«ç”Ÿæˆé€Ÿåº¦

## ğŸ¯ æ¨èå·¥ä½œæµç¤ºä¾‹

### 1. ç®€å•é—®ç­”

```
å¼€å§‹ â†’ Ollama LLM â†’ ç»“æŸ
```

**LLM èŠ‚ç‚¹é…ç½®**:
- æ¨¡å‹: `qwen2.5:3b` (å¿«é€Ÿ)
- ç³»ç»Ÿæç¤º: "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹"
- è¾“å…¥: `{{user_question}}`

### 2. å¸¦çŸ¥è¯†åº“çš„é—®ç­”

```
å¼€å§‹ â†’ çŸ¥è¯†æ£€ç´¢ â†’ Ollama LLM â†’ ç»“æŸ
```

**ä¼˜åŠ¿**: æœ¬åœ°æ¨¡å‹ + ç§æœ‰çŸ¥è¯†åº“ = å®Œå…¨ç§æœ‰åŒ–éƒ¨ç½²

### 3. å¤šæ­¥æ¨ç†

```
å¼€å§‹ â†’ Ollama (åˆ†æ) â†’ æ¡ä»¶åˆ†æ”¯ â†’ Ollama (è¯¦ç»†å›ç­”) â†’ ç»“æŸ
```

**DeepSeek-R1 ç‰¹åˆ«é€‚åˆ**: å¤æ‚æ¨ç†ä»»åŠ¡

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| æ¨¡å‹ | å¤§å° | é€Ÿåº¦ | é€‚ç”¨åœºæ™¯ |
|-----|------|------|---------|
| qwen2.5:3b | 1.9GB | âš¡âš¡âš¡ | å¿«é€Ÿé—®ç­”ã€å¯¹è¯ |
| llama3.2:7b | 4.7GB | âš¡âš¡ | é€šç”¨ä»»åŠ¡ |
| deepseek-r1:8b | 5.2GB | âš¡ | å¤æ‚æ¨ç† |

## ğŸ” å®‰å…¨ä¼˜åŠ¿

ä½¿ç”¨ Ollama çš„å¥½å¤„ï¼š

âœ… **å®Œå…¨æœ¬åœ°è¿è¡Œ** - æ•°æ®ä¸ç¦»å¼€æ‚¨çš„æœåŠ¡å™¨  
âœ… **æ—  API è´¹ç”¨** - æ— éœ€æ”¯ä»˜ OpenAI/Claude è´¹ç”¨  
âœ… **æ— é€Ÿç‡é™åˆ¶** - åªå—ç¡¬ä»¶é™åˆ¶  
âœ… **éšç§ä¿æŠ¤** - æ•æ„Ÿæ•°æ®å®Œå…¨ç§æœ‰  

## ğŸ“š ç›¸å…³èµ„æº

- [Ollama å®˜æ–¹æ–‡æ¡£](https://github.com/ollama/ollama)
- [Ollama æ¨¡å‹åº“](https://ollama.com/library)
- [Dify æ–‡æ¡£](https://docs.dify.ai/)
- [DeepSeek-R1 æ¨¡å‹ä»‹ç»](https://github.com/deepseek-ai/DeepSeek-R1)

## âœ… ä¸‹ä¸€æ­¥

1. **å¯åŠ¨ Dify API æœåŠ¡å™¨**
2. **åœ¨ Web UI ä¸­é…ç½® Ollama**
3. **åˆ›å»ºç¬¬ä¸€ä¸ªä½¿ç”¨ Ollama çš„å·¥ä½œæµ**
4. **ä½“éªŒå®Œå…¨æœ¬åœ°åŒ–çš„ LLM åº”ç”¨ï¼**

---

**éœ€è¦å¸®åŠ©ï¼Ÿ** è¿è¡Œæµ‹è¯•è„šæœ¬è¯Šæ–­é—®é¢˜ï¼š
```bash
uv run --project api python scripts/stress-test/test_ollama_quick.py
```
